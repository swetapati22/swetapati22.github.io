<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Instruction-Tuned LLMs for Event Extraction | Sweta Pati's Personal Website </title> <meta name="author" content="Sweta Pati"> <meta name="description" content="Research on enhancing event extraction using instruction-tuned large language models (LLMs), optimizing annotation guidelines, and improving fine-tuning techniques for NLP tasks."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://swetapati22.github.io/research/1_project/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Sweta Pati's Personal Website </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item active"> <a class="nav-link" href="/research/">Research Work <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/certification/">Certification </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Instruction-Tuned LLMs for Event Extraction</h1> <p class="post-description">Research on enhancing event extraction using instruction-tuned large language models (LLMs), optimizing annotation guidelines, and improving fine-tuning techniques for NLP tasks.</p> </header> <article> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>---
Research conducted at George Mason University (GMU) - Natural Language Processing Lab
Research Advisor: Dr. Ziyu Yao
Authors: Saurabh Srivastava★, Sweta Pati★, Dr. Ziyu Yao  [★ Equal contribution]
Conference Submission: ACL 2025
---
</code></pre></div></div> <hr> <h3 id="research-paper--resources"><strong>Research Paper &amp; Resources:</strong></h3> <ul> <li> <strong>ACL 2025 (Findings)</strong>: <a href="https://aclanthology.org/2025.findings-acl.677/" target="_blank" rel="external nofollow noopener">Instruction-Tuning LLMs for Event Extraction with Annotation Guidelines</a> </li> <li> <strong>Research Institution</strong>: George Mason University (GMU), NLP Lab</li> <li> <strong>Research Advisor:</strong> Dr. Ziyu Yao</li> <li> <strong>Focus Area</strong>: <strong>Event Extraction</strong>, <strong>Instruction-Tuned LLMs</strong>, <strong>Annotation Guideline Generation</strong>, <strong>LLM FineTuning</strong> </li> <li> <strong>Code Repository</strong>: <a href="https://github.com/Ziyu-Yao-NLP-Lab/PyCode-TextEE" target="_blank" rel="external nofollow noopener">PyCode-TextEE</a> </li> </ul> <hr> <blockquote> <p>⚡ <strong>TL;DR</strong>: We instruction-tune LLMs for event extraction using Python code prompts and machine-generated annotation guidelines — achieving strong generalization across domains, schemas, and model sizes with minimal supervision.</p> </blockquote> <hr> <h3 id="tech-stack--tools"><strong>Tech Stack &amp; Tools:</strong></h3> <ul> <li> <strong>NLP and Machine Learning</strong>: LLaMA-3.1-8B, LLaMA-3.2-1B, and Qwen2.5-Coder-1.5B, Hugging Face Transformers, PyTorch, LoRA Fine-Tuning, Unsloth, Quantization</li> <li> <strong>Data Processing</strong>: JSON, Python (Pandas, Numpy)</li> <li> <strong>GPU Resources</strong>: HPC clusters, CUDA-enabled GPUs</li> <li> <strong>Evaluation Metrics</strong>: Precision, Recall, F1-score</li> </ul> <hr> <h3 id="context--motivation"><strong>Context &amp; Motivation:</strong></h3> <p>Event Extraction (EE) is a fundamental task in information extraction but remains challenging due to:</p> <ul> <li>Complex schemas</li> <li>Domain shifts</li> <li>Low-resource settings</li> </ul> <p>Our work investigates how <strong>instruction-tuned LLMs</strong> can benefit from <strong>structured guidance</strong> in the form of event schemas and machine-generated annotation guidelines.</p> <hr> <div class="row justify-content-sm-center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/EE_PyCode_example-480.webp 480w,/assets/img/EE_PyCode_example-800.webp 800w,/assets/img/EE_PyCode_example-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/EE_PyCode_example.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Overview of code prompt with annotation guidelines" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <h3 id="approach"><strong>Approach:</strong></h3> <p>This research explores the <strong>enhancement of event extraction (EE) tasks</strong> by leveraging <strong>instruction-tuned large language models (LLMs)</strong>. Traditional event extraction models struggle with <strong>limited training data, ambiguous event definitions, and scalability</strong>. To address these challenges, our approach:</p> <ul> <li> <strong>Synthesized annotation guidelines using GPT-4o</strong> for: <ul> <li><strong>500+ event types</strong></li> <li><strong>4000+ argument structures</strong></li> <li>Examples include <strong>positive, negative</strong>, and <strong>sibling event types</strong> </li> <li>Removes reliance on manually written guidelines</li> </ul> </li> </ul> <div class="row justify-content-sm-center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/EE_annotation_guidelines-480.webp 480w,/assets/img/EE_annotation_guidelines-800.webp 800w,/assets/img/EE_annotation_guidelines-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/EE_annotation_guidelines.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Example for annotation guidelines" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li> <strong>Natural Language to Code-Based Prompt Conversion</strong>: <ul> <li>We provide a modular conversion script that transforms <strong>natural language event extraction data (in TextEE format)</strong> into structured <strong>Python <code class="language-plaintext highlighter-rouge">@dataclass</code> prompts</strong> with embedded <strong>annotation guidelines</strong>.</li> <li>Instruction prompts use: <ul> <li>We <strong>instruction-tune LLMs</strong> with structured prompts that represent events as Python <code class="language-plaintext highlighter-rouge">@dataclass</code> definitions.</li> <li> <strong>Annotation guidelines</strong> are integrated directly into prompt <strong>docstrings</strong>, defining triggers and arguments in natural language.</li> </ul> </li> </ul> </li> </ul> <div class="row justify-content-sm-center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/EE_code_prompt_example-480.webp 480w,/assets/img/EE_code_prompt_example-800.webp 800w,/assets/img/EE_code_prompt_example-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/EE_code_prompt_example.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Example for a code prompt with annotation guidelines" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <ul> <li> <p><strong>Fine-tuning models</strong>:<br> <strong>LLaMA-3.1 8B, LLaMA-3.2-1B, and Qwen2.5-Coder-1.5B</strong> using <strong>LoRA</strong> and <strong>structured regularization</strong></p> </li> <li> <p><strong>Designed custom evaluation framework</strong> for EE tasks designed around structured code-like annotations</p> </li> </ul> <p>This work aims to improve <strong>F1-score performance</strong> on <strong>event extraction tasks</strong> and <strong>enhance the reliability</strong> of LLM-generated event predictions.</p> <hr> <h3 id="experiments"><strong>Experiments:</strong></h3> <p>We conducted evaluations on:</p> <ul> <li> <strong>Datasets:</strong> ACE05 and RichERE</li> <li> <strong>Settings:</strong> Full-resource and low-resource (2k samples)</li> <li> <strong>Variants:</strong> With and without contrastive training (negative sampling)</li> </ul> <hr> <h3 id="key-results"><strong>Key Results:</strong></h3> <h4 id="ace05-machine-generated-guidelines-no-negative-sampling">ACE05 (machine-generated guidelines, <em>no negative sampling</em>)</h4> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- Trigger Classification (TC): +10% improvement  
- Argument Classification (AC): +5% improvement  
</code></pre></div></div> <h4 id="richere-machine-generated-guidelines-with-negative-sampling">RichERE (machine-generated guidelines, <em>with negative sampling</em>)</h4> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>- Trigger Classification (TC): +30% improvement  
- Argument Classification (AC): +25% improvement  
</code></pre></div></div> <hr> <h3 id="major-contributions"><strong>Major Contributions</strong></h3> <h4 id="1-annotation-guideline-optimization"><strong>1. Annotation Guideline Optimization</strong></h4> <ul> <li>Developed a structured framework for creating <strong>high-quality event extraction annotation guidelines</strong>.</li> <li>Synthesized event schema covering <strong>500+ event types</strong> and <strong>4000+ argument structures</strong> using <strong>GPT-4o</strong>.</li> </ul> <h4 id="2-natural-language-to-code-based-prompt-conversion"><strong>2. Natural Language to Code-Based Prompt Conversion:</strong></h4> <ul> <li>Developed a script that translates natural language event definitions into Python @dataclass-style code prompts</li> <li>These prompts include annotation guidelines as docstrings, making them executable and interpretable by LLMs</li> <li>Converts event triggers and arguments into <strong>Python-style classes</strong> </li> <li>Embeds <strong>natural language instructions</strong> as <strong>docstrings</strong> for each event type and role</li> <li>Supports <strong>automatic annotation guideline integration</strong> using synthesized or provided files</li> <li> <p>Generates <strong>LLM-compatible structured prompts</strong> for instruction tuning</p> </li> <li>This script is a core part of the pipeline that bridges textual datasets and code-style prompt learning for LLMs like LLaMA-3 and Qwen.</li> </ul> <h4 id="3-llm-fine-tuning--optimization"><strong>3. LLM Fine-Tuning &amp; Optimization</strong></h4> <ul> <li>Implemented <strong>Low-Rank Adaptation (LoRA)</strong> for <strong>fine-tuning LLaMA-3.1 8B, LLaMA-3.2-1B, and Qwen2.5-Coder-1.5B</strong> on event extraction tasks using <strong>unsloth</strong> library.</li> <li>Improved <strong>model efficiency</strong> using <strong>structured regularization</strong> techniques.</li> </ul> <h4 id="4-cost-effective--low-latency-inference-pipelines"><strong>4. Cost-Effective &amp; Low-Latency Inference Pipelines</strong></h4> <ul> <li>Designed a <strong>scalable NLP pipeline</strong> using <strong>GPU-optimized environments</strong>.</li> <li>Designed a <strong>custom evaluation framework</strong> guided by annotations for each event type for event extraction tasks as code representations.</li> </ul> <hr> <h3 id="performance-highlights"><strong>Performance Highlights:</strong></h3> <ul> <li> <strong>Machine-generated guidelines</strong> consistently outperformed <strong>human-written ones</strong>.</li> <li>The approach <strong>generalized well across domains, schema complexities, and model architectures</strong>.</li> <li>In <strong>low-data settings (2k)</strong>, models with guidelines <strong>matched or exceeded full-data baselines</strong>.</li> <li> <strong>Frequent and moderately rare event types</strong> showed notable improvement, <strong>extremely rare types remain a challenge</strong>.</li> <li>While guidelines help, we found that <strong>machine-generated guidelines consistently outperform human-written ones</strong>, and their <strong>effectiveness may or may not complement negative sampling strategies</strong>.</li> </ul> <div class="row justify-content-sm-center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/EE_evaluation_results-480.webp 480w,/assets/img/EE_evaluation_results-800.webp 800w,/assets/img/EE_evaluation_results-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/EE_evaluation_results.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Evaluation Results across different settings" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <hr> <h3 id="future-work--applications"><strong>Future Work &amp; Applications</strong></h3> <p><strong>Expanding dataset coverage</strong> to include <strong>multi-domain event extraction</strong> tasks<br> <strong>Exploring multimodal event extraction</strong> by integrating <strong>text, images, and video content</strong></p> <hr> <p><em>For collaboration or inquiries, feel free to reach out via <a href="https://www.linkedin.com/in/sweta-pati/" rel="external nofollow noopener" target="_blank">LinkedIn</a> or <a href="mailto:spati@gmu.edu">Email</a>.</em></p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Sweta Pati. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script>for(var wechatModal=document.getElementById("WeChatMod"),wechatBtn=document.querySelectorAll('[id="WeChatBtn"]'),i=0;i<wechatBtn.length;i++)wechatBtn[i].onclick=function(){wechatModal.style.display="block"};window.onclick=function(t){t.target==wechatModal&&(wechatModal.style.display="none")};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-projects",title:"Projects",description:"A growing collection of my projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-research-work",title:"Research Work",description:"Sharing my research experience.",section:"Navigation",handler:()=>{window.location.href="/research/"}},{id:"nav-certification",title:"Certification",description:"Sharing the certifications I did.",section:"Navigation",handler:()=>{window.location.href="/certification/"}},{id:"post-a-post-with-image-galleries",title:"a post with image galleries",description:"this is what included image galleries could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/photo-gallery/"}},{id:"post-google-gemini-updates-flash-1-5-gemma-2-and-project-astra",title:'Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"We\u2019re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.",section:"Posts",handler:()=>{window.open("https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/","_blank")}},{id:"post-a-post-with-tabs",title:"a post with tabs",description:"this is what included tabs in a post could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/tabs/"}},{id:"post-a-post-with-typograms",title:"a post with typograms",description:"this is what included typograms code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/typograms/"}},{id:"post-a-post-that-can-be-cited",title:"a post that can be cited",description:"this is what a post that can be cited looks like",section:"Posts",handler:()=>{window.location.href="/blog/2024/post-citation/"}},{id:"post-a-post-with-pseudo-code",title:"a post with pseudo code",description:"this is what included pseudo code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/pseudocode/"}},{id:"post-a-post-with-code-diff",title:"a post with code diff",description:"this is how you can display code diffs",section:"Posts",handler:()=>{window.location.href="/blog/2024/code-diff/"}},{id:"post-a-post-with-advanced-image-components",title:"a post with advanced image components",description:"this is what advanced image components could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/advanced-images/"}},{id:"post-a-post-with-vega-lite",title:"a post with vega lite",description:"this is what included vega lite code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/vega-lite/"}},{id:"post-a-post-with-geojson",title:"a post with geojson",description:"this is what included geojson code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/geojson-map/"}},{id:"post-a-post-with-echarts",title:"a post with echarts",description:"this is what included echarts code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/echarts/"}},{id:"post-a-post-with-chart-js",title:"a post with chart.js",description:"this is what included chart.js code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/chartjs/"}},{id:"post-a-post-with-tikzjax",title:"a post with TikZJax",description:"this is what included TikZ code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/tikzjax/"}},{id:"post-a-post-with-bibliography",title:"a post with bibliography",description:"an example of a blog post with bibliography",section:"Posts",handler:()=>{window.location.href="/blog/2023/post-bibliography/"}},{id:"post-a-post-with-jupyter-notebook",title:"a post with jupyter notebook",description:"an example of a blog post with jupyter notebook",section:"Posts",handler:()=>{window.location.href="/blog/2023/jupyter-notebook/"}},{id:"post-a-post-with-custom-blockquotes",title:"a post with custom blockquotes",description:"an example of a blog post with custom blockquotes",section:"Posts",handler:()=>{window.location.href="/blog/2023/custom-blockquotes/"}},{id:"post-a-post-with-table-of-contents-on-a-sidebar",title:"a post with table of contents on a sidebar",description:"an example of a blog post with table of contents on a sidebar",section:"Posts",handler:()=>{window.location.href="/blog/2023/sidebar-table-of-contents/"}},{id:"post-a-post-with-audios",title:"a post with audios",description:"this is what included audios could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/audios/"}},{id:"post-a-post-with-videos",title:"a post with videos",description:"this is what included videos could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/videos/"}},{id:"post-displaying-beautiful-tables-with-bootstrap-tables",title:"displaying beautiful tables with Bootstrap Tables",description:"an example of how to use Bootstrap Tables",section:"Posts",handler:()=>{window.location.href="/blog/2023/tables/"}},{id:"post-a-post-with-table-of-contents",title:"a post with table of contents",description:"an example of a blog post with table of contents",section:"Posts",handler:()=>{window.location.href="/blog/2023/table-of-contents/"}},{id:"post-a-post-with-giscus-comments",title:"a post with giscus comments",description:"an example of a blog post with giscus comments",section:"Posts",handler:()=>{window.location.href="/blog/2022/giscus-comments/"}},{id:"post-displaying-external-posts-on-your-al-folio-blog",title:'Displaying External Posts on Your al-folio Blog <svg width="1.2rem" height="1.2rem" top=".5rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2","_blank")}},{id:"post-a-post-with-redirect",title:"a post with redirect",description:"you can also redirect to assets like pdf",section:"Posts",handler:()=>{window.location.href="/assets/pdf/example_pdf.pdf"}},{id:"post-a-post-with-diagrams",title:"a post with diagrams",description:"an example of a blog post with diagrams",section:"Posts",handler:()=>{window.location.href="/blog/2021/diagrams/"}},{id:"post-a-distill-style-blog-post",title:"a distill-style blog post",description:"an example of a distill-style blog post and main elements",section:"Posts",handler:()=>{window.location.href="/blog/2021/distill/"}},{id:"post-a-post-with-twitter",title:"a post with twitter",description:"an example of a blog post with twitter",section:"Posts",handler:()=>{window.location.href="/blog/2020/twitter/"}},{id:"post-a-post-with-disqus-comments",title:"a post with disqus comments",description:"an example of a blog post with disqus comments",section:"Posts",handler:()=>{window.location.href="/blog/2015/disqus-comments/"}},{id:"post-a-post-with-math",title:"a post with math",description:"an example of a blog post with some math",section:"Posts",handler:()=>{window.location.href="/blog/2015/math/"}},{id:"post-a-post-with-code",title:"a post with code",description:"an example of a blog post with some code",section:"Posts",handler:()=>{window.location.href="/blog/2015/code/"}},{id:"post-a-post-with-images",title:"a post with images",description:"this is what included images could look like",section:"Posts",handler:()=>{window.location.href="/blog/2015/images/"}},{id:"post-a-post-with-formatting-and-links",title:"a post with formatting and links",description:"march &amp; april, looking forward to summer",section:"Posts",handler:()=>{window.location.href="/blog/2015/formatting-and-links/"}},{id:"certification-hugging-face-ai-agents-course",title:"Hugging Face - AI Agents Course",description:"Completed the Hugging Face AI Agents Course, exploring agent fundamentals, tool integration, and the Thought \u2192 Action \u2192 Observation loop, using agentic frameworks.",section:"Certification",handler:()=>{window.location.href="/certification/1_project/"}},{id:"certification-event-driven-agentic-document-workflows",title:"Event-Driven Agentic Document Workflows",description:"Completed short course by DeepLearning.AI focused on agentic workflows for automating document processing using RAG and human-in-the-loop strategies.",section:"Certification",handler:()=>{window.location.href="/certification/2_project/"}},{id:"news-i-m-thrilled-to-share-that-i-ve-begun-my-master-s-in-computer-science-specializing-in-machine-learning-at-george-mason-university",title:"I\u2019m thrilled to share that I\u2019ve begun my Master\u2019s in Computer Science, specializing...",description:"",section:"News"},{id:"news-excited-to-share-that-i-ve-joined-the-edge-mason-recreation-as-a-team-building-facilitator-graduate-professional-assistant-and-i-m-looking-forward-to-contribute-to-creating-impactful-experiences-while-further-developing-my-leadership-and-communication-skills",title:"Excited to share that I\u2019ve joined The Edge, Mason Recreation as a Team...",description:"",section:"News"},{id:"news-i-m-excited-to-announce-that-i-am-starting-a-research-assistant-position-under-the-guidance-of-prof-ziyu-yao-in-gmu-s-nlp-lab-i-will-be-working-in-the-domain-of-event-extraction-using-instruction-tuned-large-language-models-llms",title:"I\u2019m excited to announce that I am starting a Research Assistant position under...",description:"",section:"News"},{id:"news-i-m-excited-to-share-that-we-have-submitted-our-research-titled-instruction-tuning-llms-for-event-extraction-with-annotation-guidelines-to-acl-2025-under-the-guidance-of-prof-ziyu-yao",title:"I\u2019m excited to share that we have submitted our research titled Instruction-Tuning LLMs...",description:"",section:"News"},{id:"news-participated-in-bitcamp-hackathon-organized-by-university-of-maryland-college-park-and-built-techmate-turning-tech-trouble-into-tech-triumph-together-techmate-ia-a-voice-enabled-ai-assistant-designed-to-help-seniors-navigate-through-any-technology-challenges-with-confidence",title:"Participated in Bitcamp Hackathon organized by University of Maryland, College Park and built...",description:"",section:"News"},{id:"news-our-paper-instruction-tuning-llms-for-event-extraction-with-annotation-guidelines-has-been-accepted-to-acl-2025-findings-this-work-is-co-authored-with-saurabh-srivastava-and-dr-ziyu-yao-at-george-mason-university-college-of-engineering-and-computing-grateful-to-have-worked-under-the-guidance-of-prof-ziyu-yao-at-gmu-s-nlp-lab",title:"\ud83c\udf89 Our paper, Instruction-Tuning LLMs for Event Extraction with Annotation Guidelines has been...",description:"",section:"News"},{id:"news-excited-to-share-that-i-ve-joined-4a-consulting-llc-as-an-ai-ml-engineer-where-i-m-building-modular-llm-evaluation-systems-and-genai-pipelines-for-recruitment-platforms-serving-fortune-500-clients",title:"Excited to share that I\u2019ve joined 4A Consulting, LLC as an AI/ML Engineer,...",description:"",section:"News"},{id:"projects-counterhate-arguments-extending-emnlp-39-23",title:"Counterhate Arguments Extending EMNLP &amp;#39;23",description:"Reproducing and extending the EMNLP &#39;23 study on counterhate arguments for online hate speech.",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-youtube-global-statistics-analytics",title:"YouTube Global Statistics Analytics",description:"A Data Visualization project through an interactive web application, analyzing global YouTube trends by dynamic data filtering and interactive insights.",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-enhancing-gentopia-with-ai-agents",title:"Enhancing Gentopia with AI Agents",description:"Extending the Gentopia framework with a Currency Conversion Agent and a PDF Reader Agent for real-time exchange rates and document analysis.",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-multicloud-devops-amp-ai-ecommerce-platform",title:"MultiCloud, DevOps &amp;amp; AI eCommerce Platform",description:"A multi-cloud powered eCommerce platform leveraging AWS, Google Cloud, and Azure, featuring automated CI/CD pipelines, Kubernetes orchestration, AI-driven recommendations, customer support, and Azure Text Analytics with Google BigQuery Integration.",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"research-instruction-tuned-llms-for-event-extraction",title:"Instruction-Tuned LLMs for Event Extraction",description:"Research on enhancing event extraction using instruction-tuned large language models (LLMs), optimizing annotation guidelines, and improving fine-tuning techniques for NLP tasks.",section:"Research",handler:()=>{window.location.href="/research/1_project/"}},{id:"social-email",title:"email",section:"Socials",handler:()=>{window.open("mailto:%73%70%61%74%69%32%32%30%33@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"social-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/swetapati22","_blank")}},{id:"social-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/sweta-pati","_blank")}},{id:"social-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=4ZTw0IgAAAAJ","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>